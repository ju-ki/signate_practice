{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report, precision_recall_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD, SparsePCA, LatentDirichletAllocation\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import sentencepiece as spm\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./input/train_data.csv\")\n",
    "test_df = pd.read_csv(\"./input/test_data.csv\")\n",
    "\n",
    "train_length = len(train_df)\n",
    "test_length = len(test_df)\n",
    "\n",
    "# number of spam and ham -------------------------------------------------------\n",
    "n_train_not_spam = 8707\n",
    "n_train_spam = 171\n",
    "n_test_not_spam = 7838\n",
    "n_test_spam = 17000\n",
    "\n",
    "test_not_spam_ration = n_test_not_spam/n_test_spam  # 7838 / 17000\n",
    "test_spam_ration = n_test_spam / n_test_not_spam  # 17000 / 7838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __remove_head(self, X):\n",
    "        \"\"\"先頭のSubject:を削除\"\"\"\n",
    "        X_series = pd.Series(X)\n",
    "        if X_series.str.startswith(\"Subject:\").all():\n",
    "            X_series = X_series.apply(lambda c: c[9:])\n",
    "        X = X_series.values\n",
    "        return X\n",
    "    \n",
    "    def preprocess(self, X):\n",
    "        X = X.copy()\n",
    "        X = self.__remove_head(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencePieceTokenizer:\n",
    "    def __init__(self, model_prefix, vocab_size=5000, \n",
    "                user_defined_symbols = (\"(\",\")\",\"\\\"\",\"-\",\".\",\"–\",\"£\",\"€\"),\n",
    "                shuffle_input_sentence = True, character_coverage=1.0,\n",
    "                model_type=\"unigram\"):\n",
    "        self.processor = spm.SentencePieceProcessor()\n",
    "        self.model_prefix = model_prefix\n",
    "        self.vocab_size = vocab_size\n",
    "        self.user_defined_symbols = user_defined_symbols\n",
    "        self.shuffle_input_sentence = shuffle_input_sentence\n",
    "        self.character_coverage = character_coverage\n",
    "        self.model_type = model_type\n",
    "    def __call__(self, raw_document):\n",
    "        return self.tokenize(raw_document)\n",
    "    \n",
    "    def tokenize(self, raw_document):\n",
    "        return self.processor.EncodeAsPieces(raw_document)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        document_file = f\"{self.model_prefix}.txt\"\n",
    "        # すべての文字列をテキストファイルに書き出す\n",
    "        print(*X, sep=\"\\n\", file=codecs.open(document_file, \"w\", \"utf-8\"))\n",
    "        spm.SentencePieceTrainer.Train(\n",
    "            input = document_file,\n",
    "            model_prefix = self.model_prefix,\n",
    "            vocab_size = self.vocab_size,\n",
    "            user_defined_symbols = self.user_defined_symbols,\n",
    "            shuffle_input_sentence = self.shuffle_input_sentence,\n",
    "            character_coverage = self.character_coverage,\n",
    "            model_type = self.model_type\n",
    "        )\n",
    "        model_name = f\"{self.model_prefix}.model\"\n",
    "        self.processor.Load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_not_spam = train_df[\"y\"] == 0\n",
    "is_spam = train_df[\"y\"] == 1\n",
    "\n",
    "is_not_spam_index = np.where(is_not_spam)[0]\n",
    "is_spam_index = np.where(is_spam)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(train_df[\"contents\"])\n",
    "y = pd.DataFrame(train_df[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Dictionary\n",
    "tokenizer_cls_dict = {\n",
    "    \"SentencePieceTokenizer\":SentencePieceTokenizer\n",
    "}\n",
    "\n",
    "vectorizer_cls_dict = {\n",
    "    \"CountVectorizer\": CountVectorizer,\n",
    "    \"TfidfVectorizer\": TfidfVectorizer\n",
    "}\n",
    "\n",
    "decomposition_cls_dict = {\n",
    "    \"NMF\":NMF, \"PCA\":PCA, \"SparsePCA\":SparsePCA, \n",
    "    \"TruncatedSVD\":TruncatedSVD,\n",
    "    \"LatentDirichletAllocation\":LatentDirichletAllocation\n",
    "}\n",
    "\n",
    "model_cls_dict = {\n",
    "    \"MultinomialNB\":MultinomialNB,\n",
    "    \"LGBMClassifier\":LGBMClassifier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 20\n",
    "tokenizer_name = \"SentencePieceTokenizer\"\n",
    "tokenizer_params = {\n",
    "    \"model_prefix\": \"train\",\n",
    "    \"vocab_size\": 2247,  # 5000,\n",
    "    \"user_defined_symbols\": [\"(\",\")\",\"\\\"\",\"-\",\".\",\"–\",\"£\",\"€\"],\n",
    "    \"shuffle_input_sentence\": True,\n",
    "    \"character_coverage\": 1.0,\n",
    "    \"model_type\": \"unigram\"}\n",
    "\n",
    "vectorizer_name = \"CountVectorizer\"\n",
    "vectorizer_params = {\n",
    "    \"min_df\": 0.0019210379695393533,  # 2\n",
    "    \"max_df\": 0.1501408652009228,  # 0.7\n",
    "    \"ngram_range\": (1, 2),  # (1, 1),\n",
    "    \"stop_words\": None,\n",
    "    \"token_pattern\": None}\n",
    "\n",
    "model_name = \"MultinomialNB\"\n",
    "model_params = {}\n",
    "model_fit_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word size:  44114\n",
      "word content:  {'ke': 12705, 'to': 19660, 'ck': 6783, '▁success': 40167, '▁structure': 40100}\n",
      "val_F1-score 0.6428571428571429\n",
      "downsampled_val_F1-score 0.9473684210526316\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9817    0.9989    0.9902      8707\n",
      "        spam     0.4737    0.0526    0.0947       171\n",
      "\n",
      "    accuracy                         0.9806      8878\n",
      "   macro avg     0.7277    0.5257    0.5425      8878\n",
      "weighted avg     0.9719    0.9806    0.9730      8878\n",
      "\n",
      "oof_F1-score 0.09473684210526316\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.3250    1.0000    0.4906        78\n",
      "        spam     1.0000    0.0526    0.1000       171\n",
      "\n",
      "    accuracy                         0.3494       249\n",
      "   macro avg     0.6625    0.5263    0.2953       249\n",
      "weighted avg     0.7886    0.3494    0.2223       249\n",
      "\n",
      "resampled oof_F1-score 0.1\n",
      "\n",
      "word size:  49470\n",
      "word content:  {'▁key': 36953, 'ck': 7470, '▁success': 44850, '▁structure': 44782, '&': 372}\n",
      "val_F1-score 0.5454545454545454\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9827    0.9971    0.9899      8707\n",
      "        spam     0.4186    0.1053    0.1682       171\n",
      "\n",
      "    accuracy                         0.9800      8878\n",
      "   macro avg     0.7006    0.5512    0.5790      8878\n",
      "weighted avg     0.9718    0.9800    0.9740      8878\n",
      "\n",
      "oof_F1-score 0.16822429906542058\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.3377    1.0000    0.5049        78\n",
      "        spam     1.0000    0.1053    0.1905       171\n",
      "\n",
      "    accuracy                         0.3855       249\n",
      "   macro avg     0.6688    0.5526    0.3477       249\n",
      "weighted avg     0.7925    0.3855    0.2890       249\n",
      "\n",
      "resampled oof_F1-score 0.1904761904761905\n",
      "\n",
      "word size:  56199\n",
      "word content:  {'ck': 7942, '▁success': 50941, 'structure': 22655, '&': 434, '▁technolog': 51240}\n",
      "val_F1-score 0.4864864864864865\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9836    0.9949    0.9893      8707\n",
      "        spam     0.3803    0.1579    0.2231       171\n",
      "\n",
      "    accuracy                         0.9788      8878\n",
      "   macro avg     0.6820    0.5764    0.6062      8878\n",
      "weighted avg     0.9720    0.9788    0.9745      8878\n",
      "\n",
      "oof_F1-score 0.2231404958677686\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.3514    1.0000    0.5200        78\n",
      "        spam     1.0000    0.1579    0.2727       171\n",
      "\n",
      "    accuracy                         0.4217       249\n",
      "   macro avg     0.6757    0.5789    0.3964       249\n",
      "weighted avg     0.7968    0.4217    0.3502       249\n",
      "\n",
      "resampled oof_F1-score 0.2727272727272727\n",
      "\n",
      "word size:  41412\n",
      "word content:  {'to': 18519, 'ck': 6610, '▁success': 37657, '▁structure': 37602, '&': 340}\n",
      "val_F1-score 0.35294117647058826\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9846    0.9912    0.9879      8707\n",
      "        spam     0.3186    0.2105    0.2535       171\n",
      "\n",
      "    accuracy                         0.9761      8878\n",
      "   macro avg     0.6516    0.6008    0.6207      8878\n",
      "weighted avg     0.9718    0.9761    0.9737      8878\n",
      "\n",
      "oof_F1-score 0.2535211267605633\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.3632    0.9872    0.5310        78\n",
      "        spam     0.9730    0.2105    0.3462       171\n",
      "\n",
      "    accuracy                         0.4538       249\n",
      "   macro avg     0.6681    0.5989    0.4386       249\n",
      "weighted avg     0.7820    0.4538    0.4041       249\n",
      "\n",
      "resampled oof_F1-score 0.34615384615384615\n",
      "\n",
      "word size:  43776\n",
      "word content:  {'ke': 12534, 'to': 19191, 'ck': 6597, '▁success': 39758, 'structure': 18376}\n",
      "val_F1-score 0.5517241379310346\n",
      "downsampled_val_F1-score 0.9411764705882353\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9855    0.9898    0.9876      8707\n",
      "        spam     0.3308    0.2573    0.2895       171\n",
      "\n",
      "    accuracy                         0.9757      8878\n",
      "   macro avg     0.6582    0.6235    0.6385      8878\n",
      "weighted avg     0.9729    0.9757    0.9742      8878\n",
      "\n",
      "oof_F1-score 0.28947368421052627\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.3805    1.0000    0.5512        78\n",
      "        spam     1.0000    0.2573    0.4093       171\n",
      "\n",
      "    accuracy                         0.4900       249\n",
      "   macro avg     0.6902    0.6287    0.4803       249\n",
      "weighted avg     0.8059    0.4900    0.4538       249\n",
      "\n",
      "resampled oof_F1-score 0.40930232558139534\n",
      "\n",
      "word size:  45211\n",
      "word content:  {'key': 12760, 'to': 20034, 'ck': 6461, '▁success': 41156, '▁structure': 41071}\n",
      "val_F1-score 0.47058823529411764\n",
      "downsampled_val_F1-score 0.9411764705882353\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9864    0.9878    0.9871      8707\n",
      "        spam     0.3291    0.3041    0.3161       171\n",
      "\n",
      "    accuracy                         0.9747      8878\n",
      "   macro avg     0.6577    0.6460    0.6516      8878\n",
      "weighted avg     0.9737    0.9747    0.9742      8878\n",
      "\n",
      "oof_F1-score 0.3161094224924012\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.3929    0.9872    0.5620        78\n",
      "        spam     0.9811    0.3041    0.4643       171\n",
      "\n",
      "    accuracy                         0.5181       249\n",
      "   macro avg     0.6870    0.6456    0.5132       249\n",
      "weighted avg     0.7969    0.5181    0.4949       249\n",
      "\n",
      "resampled oof_F1-score 0.4642857142857143\n",
      "\n",
      "word size:  42442\n",
      "word content:  {'key': 12063, 'to': 18561, 'ck': 6294, '▁success': 38638, 'structure': 17759}\n",
      "val_F1-score 0.43902439024390244\n",
      "downsampled_val_F1-score 0.9473684210526316\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9873    0.9852    0.9863      8707\n",
      "        spam     0.3211    0.3567    0.3380       171\n",
      "\n",
      "    accuracy                         0.9731      8878\n",
      "   macro avg     0.6542    0.6710    0.6621      8878\n",
      "weighted avg     0.9745    0.9731    0.9738      8878\n",
      "\n",
      "oof_F1-score 0.3379501385041551\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.4054    0.9615    0.5703        78\n",
      "        spam     0.9531    0.3567    0.5191       171\n",
      "\n",
      "    accuracy                         0.5462       249\n",
      "   macro avg     0.6793    0.6591    0.5447       249\n",
      "weighted avg     0.7816    0.5462    0.5352       249\n",
      "\n",
      "resampled oof_F1-score 0.5191489361702128\n",
      "\n",
      "word size:  45827\n",
      "word content:  {'▁key': 34518, 'to': 20093, 'ck': 6897, '▁success': 41608, '▁structure': 41528}\n",
      "val_F1-score 0.4615384615384615\n",
      "downsampled_val_F1-score 0.9473684210526316\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9883    0.9828    0.9855      8707\n",
      "        spam     0.3182    0.4094    0.3581       171\n",
      "\n",
      "    accuracy                         0.9717      8878\n",
      "   macro avg     0.6533    0.6961    0.6718      8878\n",
      "weighted avg     0.9754    0.9717    0.9735      8878\n",
      "\n",
      "oof_F1-score 0.3580562659846547\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.4326    0.9872    0.6016        78\n",
      "        spam     0.9859    0.4094    0.5785       171\n",
      "\n",
      "    accuracy                         0.5904       249\n",
      "   macro avg     0.7092    0.6983    0.5900       249\n",
      "weighted avg     0.8126    0.5904    0.5857       249\n",
      "\n",
      "resampled oof_F1-score 0.5785123966942148\n",
      "\n",
      "word size:  46772\n",
      "word content:  {'▁aggressive': 25496, '▁investor': 34732, '▁should': 41825, 'watch': 21376, '▁sports': 42255}\n",
      "val_F1-score 0.5517241379310346\n",
      "downsampled_val_F1-score 0.9411764705882353\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9892    0.9814    0.9853      8707\n",
      "        spam     0.3250    0.4561    0.3796       171\n",
      "\n",
      "    accuracy                         0.9713      8878\n",
      "   macro avg     0.6571    0.7188    0.6824      8878\n",
      "weighted avg     0.9764    0.9713    0.9736      8878\n",
      "\n",
      "oof_F1-score 0.37956204379562036\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.4529    0.9872    0.6210        78\n",
      "        spam     0.9873    0.4561    0.6240       171\n",
      "\n",
      "    accuracy                         0.6225       249\n",
      "   macro avg     0.7201    0.7217    0.6225       249\n",
      "weighted avg     0.8199    0.6225    0.6231       249\n",
      "\n",
      "resampled oof_F1-score 0.624\n",
      "\n",
      "word size:  43527\n",
      "word content:  {'▁key': 33012, 'to': 19504, 'ck': 6641, '▁success': 39503, '▁structure': 39432}\n",
      "val_F1-score 0.5294117647058824\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9902    0.9796    0.9849      8707\n",
      "        spam     0.3283    0.5088    0.3991       171\n",
      "\n",
      "    accuracy                         0.9705      8878\n",
      "   macro avg     0.6593    0.7442    0.6920      8878\n",
      "weighted avg     0.9775    0.9705    0.9736      8878\n",
      "\n",
      "oof_F1-score 0.3990825688073395\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.4783    0.9872    0.6444        78\n",
      "        spam     0.9886    0.5088    0.6718       171\n",
      "\n",
      "    accuracy                         0.6586       249\n",
      "   macro avg     0.7334    0.7480    0.6581       249\n",
      "weighted avg     0.8288    0.6586    0.6632       249\n",
      "\n",
      "resampled oof_F1-score 0.6718146718146719\n",
      "\n",
      "word size:  53087\n",
      "word content:  {'▁key': 39623, 'to': 22063, 'ck': 7627, '▁success': 48030, 'structure': 21119}\n",
      "val_F1-score 0.6\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9913    0.9782    0.9847      8707\n",
      "        spam     0.3357    0.5614    0.4201       171\n",
      "\n",
      "    accuracy                         0.9702      8878\n",
      "   macro avg     0.6635    0.7698    0.7024      8878\n",
      "weighted avg     0.9786    0.9702    0.9738      8878\n",
      "\n",
      "oof_F1-score 0.42013129102844643\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.5098    1.0000    0.6753        78\n",
      "        spam     1.0000    0.5614    0.7191       171\n",
      "\n",
      "    accuracy                         0.6988       249\n",
      "   macro avg     0.7549    0.7807    0.6972       249\n",
      "weighted avg     0.8464    0.6988    0.7054       249\n",
      "\n",
      "resampled oof_F1-score 0.7191011235955056\n",
      "\n",
      "word size:  45695\n",
      "word content:  {'▁ke': 34444, 'to': 19901, 'ck': 7046, '▁success': 41484, '▁structure': 41416}\n",
      "val_F1-score 0.47058823529411764\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9922    0.9761    0.9841      8707\n",
      "        spam     0.3333    0.6082    0.4306       171\n",
      "\n",
      "    accuracy                         0.9690      8878\n",
      "   macro avg     0.6628    0.7921    0.7074      8878\n",
      "weighted avg     0.9795    0.9690    0.9734      8878\n",
      "\n",
      "oof_F1-score 0.4306418219461698\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.5347    0.9872    0.6937        78\n",
      "        spam     0.9905    0.6082    0.7536       171\n",
      "\n",
      "    accuracy                         0.7269       249\n",
      "   macro avg     0.7626    0.7977    0.7237       249\n",
      "weighted avg     0.8477    0.7269    0.7349       249\n",
      "\n",
      "resampled oof_F1-score 0.7536231884057971\n",
      "\n",
      "word size:  51462\n",
      "word content:  {'▁key': 38319, 'to': 21278, 'ck': 6806, '▁success': 46555, '▁structure': 46475}\n",
      "val_F1-score 0.48484848484848486\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9931    0.9742    0.9835      8707\n",
      "        spam     0.3323    0.6550    0.4409       171\n",
      "\n",
      "    accuracy                         0.9680      8878\n",
      "   macro avg     0.6627    0.8146    0.7122      8878\n",
      "weighted avg     0.9804    0.9680    0.9731      8878\n",
      "\n",
      "oof_F1-score 0.4409448818897638\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.5597    0.9615    0.7075        78\n",
      "        spam     0.9739    0.6550    0.7832       171\n",
      "\n",
      "    accuracy                         0.7510       249\n",
      "   macro avg     0.7668    0.8083    0.7454       249\n",
      "weighted avg     0.8442    0.7510    0.7595       249\n",
      "\n",
      "resampled oof_F1-score 0.7832167832167832\n",
      "\n",
      "word size:  45309\n",
      "word content:  {'▁key': 34388, 'to': 20134, 'ck': 6875, '▁success': 41258, '▁structur': 41185}\n",
      "val_F1-score 0.5333333333333333\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9940    0.9726    0.9832      8707\n",
      "        spam     0.3343    0.7018    0.4528       171\n",
      "\n",
      "    accuracy                         0.9673      8878\n",
      "   macro avg     0.6641    0.8372    0.7180      8878\n",
      "weighted avg     0.9813    0.9673    0.9730      8878\n",
      "\n",
      "oof_F1-score 0.45283018867924524\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.5984    0.9744    0.7415        78\n",
      "        spam     0.9836    0.7018    0.8191       171\n",
      "\n",
      "    accuracy                         0.7871       249\n",
      "   macro avg     0.7910    0.8381    0.7803       249\n",
      "weighted avg     0.8629    0.7871    0.7948       249\n",
      "\n",
      "resampled oof_F1-score 0.8191126279863481\n",
      "\n",
      "word size:  44011\n",
      "word content:  {'▁key': 33176, 'to': 19376, 'ck': 6781, '▁success': 40024, 'structure': 18567}\n",
      "val_F1-score 0.5333333333333333\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9949    0.9709    0.9828      8707\n",
      "        spam     0.3360    0.7485    0.4638       171\n",
      "\n",
      "    accuracy                         0.9667      8878\n",
      "   macro avg     0.6654    0.8597    0.7233      8878\n",
      "weighted avg     0.9822    0.9667    0.9728      8878\n",
      "\n",
      "oof_F1-score 0.46376811594202894\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.6417    0.9872    0.7778        78\n",
      "        spam     0.9922    0.7485    0.8533       171\n",
      "\n",
      "    accuracy                         0.8233       249\n",
      "   macro avg     0.8170    0.8679    0.8156       249\n",
      "weighted avg     0.8824    0.8233    0.8297       249\n",
      "\n",
      "resampled oof_F1-score 0.8533333333333334\n",
      "\n",
      "word size:  44782\n",
      "word content:  {'key': 12630, 'to': 19720, 'ck': 6751, '▁success': 40688, '▁structure': 40614}\n",
      "val_F1-score 0.38095238095238093\n",
      "downsampled_val_F1-score 0.9411764705882353\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9959    0.9680    0.9817      8707\n",
      "        spam     0.3277    0.7953    0.4642       171\n",
      "\n",
      "    accuracy                         0.9646      8878\n",
      "   macro avg     0.6618    0.8816    0.7229      8878\n",
      "weighted avg     0.9830    0.9646    0.9717      8878\n",
      "\n",
      "oof_F1-score 0.46416382252559735\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.6818    0.9615    0.7979        78\n",
      "        spam     0.9784    0.7953    0.8774       171\n",
      "\n",
      "    accuracy                         0.8474       249\n",
      "   macro avg     0.8301    0.8784    0.8376       249\n",
      "weighted avg     0.8855    0.8474    0.8525       249\n",
      "\n",
      "resampled oof_F1-score 0.8774193548387096\n",
      "\n",
      "word size:  45099\n",
      "word content:  {'▁key': 34223, 'to': 19194, 'ck': 6413, '▁success': 40968, 'structure': 18564}\n",
      "val_F1-score 0.4516129032258065\n",
      "downsampled_val_F1-score 0.9333333333333333\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9967    0.9661    0.9812      8707\n",
      "        spam     0.3265    0.8363    0.4696       171\n",
      "\n",
      "    accuracy                         0.9636      8878\n",
      "   macro avg     0.6616    0.9012    0.7254      8878\n",
      "weighted avg     0.9838    0.9636    0.9713      8878\n",
      "\n",
      "oof_F1-score 0.4696223316912972\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.7308    0.9744    0.8352        78\n",
      "        spam     0.9862    0.8363    0.9051       171\n",
      "\n",
      "    accuracy                         0.8795       249\n",
      "   macro avg     0.8585    0.9053    0.8701       249\n",
      "weighted avg     0.9062    0.8795    0.8832       249\n",
      "\n",
      "resampled oof_F1-score 0.9050632911392406\n",
      "\n",
      "word size:  44439\n",
      "word content:  {'▁key': 33463, 'to': 19710, 'ck': 6642, '▁success': 40196, '▁structure': 40142}\n",
      "val_F1-score 0.45714285714285713\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9976    0.9639    0.9805      8707\n",
      "        spam     0.3247    0.8830    0.4748       171\n",
      "\n",
      "    accuracy                         0.9624      8878\n",
      "   macro avg     0.6612    0.9235    0.7277      8878\n",
      "weighted avg     0.9847    0.9624    0.9708      8878\n",
      "\n",
      "oof_F1-score 0.47484276729559743\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.7849    0.9359    0.8538        78\n",
      "        spam     0.9679    0.8830    0.9235       171\n",
      "\n",
      "    accuracy                         0.8996       249\n",
      "   macro avg     0.8764    0.9095    0.8887       249\n",
      "weighted avg     0.9106    0.8996    0.9017       249\n",
      "\n",
      "resampled oof_F1-score 0.9235474006116208\n",
      "\n",
      "word size:  43268\n",
      "word content:  {'▁key': 32621, 'to': 19190, 'ck': 6582, '▁success': 39190, '▁structur': 39127}\n",
      "val_F1-score 0.5161290322580645\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9986    0.9622    0.9801      8707\n",
      "        spam     0.3258    0.9298    0.4825       171\n",
      "\n",
      "    accuracy                         0.9616      8878\n",
      "   macro avg     0.6622    0.9460    0.7313      8878\n",
      "weighted avg     0.9856    0.9616    0.9705      8878\n",
      "\n",
      "oof_F1-score 0.4825493171471928\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.8621    0.9615    0.9091        78\n",
      "        spam     0.9815    0.9298    0.9550       171\n",
      "\n",
      "    accuracy                         0.9398       249\n",
      "   macro avg     0.9218    0.9457    0.9320       249\n",
      "weighted avg     0.9441    0.9398    0.9406       249\n",
      "\n",
      "resampled oof_F1-score 0.954954954954955\n",
      "\n",
      "word size:  43076\n",
      "word content:  {'▁key': 32387, 'to': 18973, 'ck': 6550, '▁success': 39056, 'structure': 18134}\n",
      "val_F1-score 0.4324324324324324\n",
      "downsampled_val_F1-score 1.0\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9995    0.9598    0.9793      8707\n",
      "        spam     0.3230    0.9766    0.4855       171\n",
      "\n",
      "    accuracy                         0.9601      8878\n",
      "   macro avg     0.6613    0.9682    0.7324      8878\n",
      "weighted avg     0.9865    0.9601    0.9697      8878\n",
      "\n",
      "oof_F1-score 0.48546511627906974\n",
      "\n",
      "resampled:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    not_spam     0.9487    0.9487    0.9487        78\n",
      "        spam     0.9766    0.9766    0.9766       171\n",
      "\n",
      "    accuracy                         0.9679       249\n",
      "   macro avg     0.9627    0.9627    0.9627       249\n",
      "weighted avg     0.9679    0.9679    0.9679       249\n",
      "\n",
      "resampled oof_F1-score 0.9766081871345029\n",
      "\n",
      "sample f1 scores: [0.9681159420289854, 0.9766081871345029, 0.9823529411764705, 0.9794721407624634, 0.9766081871345029, 0.9794721407624634, 0.9766081871345029, 0.9823529411764705, 0.9794721407624634, 0.9823529411764705, 0.9766081871345029, 0.9766081871345029, 0.9794721407624634, 0.9823529411764705, 0.9794721407624634, 0.9737609329446064, 0.9766081871345029, 0.9794721407624634, 0.9823529411764705, 0.9794721407624634]\n",
      "mean sample f1 score: 0.9784797844500103\n"
     ]
    }
   ],
   "source": [
    "val_preds = np.zeros(train_length)\n",
    "preds = []\n",
    "preprocessor = Preprocessor()\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "\n",
    "for (train_index_spam, val_index_spam), (train_index_not_spam, val_index_not_spam) in zip(kfold.split(is_spam_index), kfold.split(is_not_spam_index)):\n",
    "    # print(train_index_spam.shape, val_index_spam.shape, train_index_not_spam.shape, val_index_not_spam.shape)\n",
    "    # print(train_index_spam, val_index_spam, train_index_not_spam, val_index_not_spam)\n",
    "\n",
    "    # downsampling ---------------------------------------------------------------\n",
    "    n_train_spam = len(train_index_spam)\n",
    "    train_index_not_spam = np.random.choice(train_index_not_spam, n_train_spam, replace=False)\n",
    "    n_val_spam = len(val_index_spam)\n",
    "    val_index_not_spam_downsampled = np.random.choice(val_index_not_spam, n_val_spam, replace=False)\n",
    "\n",
    "    train_index = np.concatenate((is_spam_index[train_index_spam], is_not_spam_index[train_index_not_spam]), axis=0)\n",
    "    val_index = np.concatenate((is_spam_index[val_index_spam], is_not_spam_index[val_index_not_spam]), axis=0)\n",
    "    val_index_downsampled = np.concatenate((is_spam_index[val_index_spam], is_not_spam_index[val_index_not_spam_downsampled]), axis=0)\n",
    "\n",
    "    X_resampled = X.loc[train_index, \"contents\"].values\n",
    "    y_resampled = y.loc[train_index, \"y\"].values\n",
    "    X_val = X.loc[val_index, \"contents\"].values\n",
    "    y_val = y.loc[val_index, \"y\"].values\n",
    "    X_val_downsampled = X.loc[val_index_downsampled, \"contents\"].values\n",
    "    y_val_downsampled = y.loc[val_index_downsampled, \"y\"].values\n",
    "\n",
    "    # preprocess -----------------------------------------------------------------\n",
    "    X_resampled = preprocessor.preprocess(X_resampled)\n",
    "    X_val = preprocessor.preprocess(X_val)\n",
    "    X_val_downsampled = preprocessor.preprocess(X_val_downsampled)\n",
    "\n",
    "    # tokenizer ------------------------------------------------------------------\n",
    "    tokenizer = tokenizer_cls_dict[tokenizer_name](**tokenizer_params)\n",
    "    tokenizer.fit(X_resampled)\n",
    "\n",
    "    # vectorizer -----------------------------------------------------------------\n",
    "    vectorizer = vectorizer_cls_dict[vectorizer_name](tokenizer=tokenizer, **vectorizer_params)\n",
    "    vectorizer.fit(X_resampled)\n",
    "\n",
    "    # 単語の出現回数取得 ---------------------------------------------------------\n",
    "    # 単語の種類の表示\n",
    "    print('word size: ', len(vectorizer.vocabulary_))\n",
    "    # 先頭５件の単語を表示\n",
    "    print('word content: ', dict(list(vectorizer.vocabulary_.items())[0:5]))\n",
    "\n",
    "    # 訓練データと検証データをベクトル化 -----------------------------------------\n",
    "    X_resampled_vec = vectorizer.transform(X_resampled)\n",
    "    X_val_vec = vectorizer.transform(X_val)\n",
    "    X_val_vec_downsampled = vectorizer.transform(X_val_downsampled)\n",
    "\n",
    "    # 学習 -----------------------------------------------------------------------\n",
    "    model = model_cls_dict[model_name](**model_params)\n",
    "    model.fit(X_resampled_vec, y_resampled, **model_fit_params)\n",
    "\n",
    "    # validation data の予測 -----------------------------------------------------\n",
    "    val_pred = model.predict_proba(X_val_vec)[:, 1]\n",
    "    val_preds[val_index] = val_pred\n",
    "    val_pred_downsampled = model.predict_proba(X_val_vec_downsampled)[:, 1]\n",
    "\n",
    "    # F1スコアのprint\n",
    "    print(\"val_F1-score\",f1_score(y_val, np.where(val_pred>0.5, 1, 0)))\n",
    "    print(\"downsampled_val_F1-score\",f1_score(y_val_downsampled, np.where(val_pred_downsampled>0.5, 1, 0)))\n",
    "    print(\"------------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    # testデータをベクトル化\n",
    "    # df_data = pd.DataFrame(test, columns=['contents'])\n",
    "    input_vec = vectorizer.transform(preprocessor.preprocess(test_df['contents'].values))\n",
    "\n",
    "    # testの予測→seed毎に空のリストに格納\n",
    "    pred = model.predict_proba(input_vec)\n",
    "    preds.append(pred)\n",
    "    # end for ----------------------------------------------------------------------\n",
    "\n",
    "    # Classification Report --------------------------------------------------------\n",
    "    print()\n",
    "    print(classification_report(y[\"y\"].values, np.where(val_preds>0.5, 1, 0), digits=4, target_names=[\"not_spam\", \"spam\"]))\n",
    "    print(\"oof_F1-score\",f1_score(y[\"y\"].values, np.where(val_preds>0.5, 1, 0)))\n",
    "    print()\n",
    "\n",
    "    # resampled classification report\n",
    "    n_sample_not_spam_index = int(len(is_spam_index) * test_not_spam_ration)\n",
    "    sample_not_spam_index = np.random.choice(is_not_spam_index, n_sample_not_spam_index, replace=False)\n",
    "    sample_index = np.concatenate((sample_not_spam_index, is_spam_index))\n",
    "    print(\"resampled:\")\n",
    "    print(classification_report(y.loc[sample_index, \"y\"].values, np.where(val_preds[sample_index]>0.5, 1, 0), digits=4, target_names=[\"not_spam\", \"spam\"]))\n",
    "    print(\"resampled oof_F1-score\",f1_score(y.loc[sample_index, \"y\"].values, np.where(val_preds[sample_index]>0.5, 1, 0)))\n",
    "    print()\n",
    "\n",
    "    # Average resampled F1 score ---------------------------------------------------\n",
    "    sample_scores = []\n",
    "    n_sample_scores = 20  # Nunmber of downsampled F1 scores\n",
    "for i in range(n_sample_scores):\n",
    "    n_sample_not_spam_index = int(len(is_spam_index) * test_not_spam_ration)\n",
    "    sample_not_spam_index = np.random.choice(is_not_spam_index, n_sample_not_spam_index, replace=False)\n",
    "    sample_index = np.concatenate((sample_not_spam_index, is_spam_index))\n",
    "    # print(\"resampled:\")\n",
    "    # print(classification_report(y.loc[sample_index, \"y\"].values, np.where(val_preds[sample_index]>0.5, 1, 0), digits=4, target_names=[\"not_spam\", \"spam\"]))\n",
    "    sample_score = f1_score(y.loc[sample_index, \"y\"].values, np.where(val_preds[sample_index]>0.5, 1, 0))\n",
    "    # print(\"resampled oof_F1-score\",sample_score)\n",
    "    sample_scores.append(sample_score)\n",
    "print(\"sample f1 scores:\", sample_scores)\n",
    "print(\"mean sample f1 score:\", np.mean(sample_scores))\n",
    "\n",
    "# To Numpy Array ---------------------------------------------------------------\n",
    "preds = np.array(preds)\n",
    "preds = preds[:, :, 1]\n",
    "\n",
    "preds_mean = preds.mean(axis=0)  # The mean of the prediction for the test data for each CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "is_spam_index_ = y[\"y\"] == 1\n",
    "print(sum(y.loc[is_spam_index_, \"y\"].values == np.where(val_preds[is_spam_index_]>threshold, 1, 0)) / len(y[is_spam_index_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.hist(val_preds[~is_spam_index_], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_preds[is_spam_index_], bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
